{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 3 (2 points) Compute the optimal policy using policy iteration. \n",
    "How many iterations are necessary to achieve convergence?\n",
    "\n",
    "Document:\n",
    "- For which states the action is “do nothing” vs. “do maintenance”. \n",
    "- The total expected discounted cost per state.\n",
    "- The number of iterations needed for convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## States, action space and cost (reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 98 states in our MDP.\n"
     ]
    }
   ],
   "source": [
    "# degradation thresholds\n",
    "xi = {1: 15, 2: 30, 3: 50}\n",
    "\n",
    "# State space\n",
    "S = []\n",
    "for T in [1, 2, 3]:\n",
    "    for d in range(xi[T]+1):\n",
    "        S.append((T, d))\n",
    "\n",
    "# Get total number of states\n",
    "num_states = len(S)\n",
    "print(f\"There are {len(S)} states in our MDP.\")\n",
    "\n",
    "# Action space\n",
    "A = [0, 1]  # 0: \"Do nothing\", 1: \"Do maintenance\"\n",
    "\n",
    "# Cost function C[s][a] where s is current state, a is action\n",
    "C = np.zeros((num_states, 2))\n",
    "\n",
    "\n",
    "for idx_s, s in enumerate(S):\n",
    "    T, d = s\n",
    "\n",
    "    if d == xi[T]:\n",
    "        C[idx_s][0] = float(\"inf\")\n",
    "        C[idx_s][1] = 5\n",
    "    else:\n",
    "        C[idx_s][0] = 0\n",
    "        C[idx_s][1] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transition probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_param = 4\n",
    "pi = 0.5\n",
    "\n",
    "def zero_inflated_poisson_pmf(k, lambda_param=lambda_param, pi=pi):\n",
    "    if k == 0:\n",
    "        return pi + (1 - pi) * np.exp(-lambda_param)\n",
    "    else:\n",
    "        return (1 - pi) * (np.power(lambda_param, k) * np.exp(-lambda_param)) / math.factorial(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum k needed for sufficient precision: 30\n"
     ]
    }
   ],
   "source": [
    "# Calculate the maximum k needed for zero-inflated Poisson\n",
    "def find_max_k(lambda_param=lambda_param, pi=pi, epsilon=np.finfo(float).eps):\n",
    "    k = 0\n",
    "    while True:\n",
    "        # Calculate probability for this k\n",
    "        prob = zero_inflated_poisson_pmf(k, lambda_param, pi)\n",
    "        \n",
    "        # If probability is below floating-point precision, we've found our cutoff\n",
    "        if prob < epsilon:\n",
    "            return k\n",
    "        k += 1\n",
    "\n",
    "# Calculate the maximum k needed once\n",
    "max_k = find_max_k()\n",
    "print(f\"Maximum k needed for sufficient precision: {max_k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transition probability matrices created with shape: (2, 98, 98)\n"
     ]
    }
   ],
   "source": [
    "# P[a][s][s'] where a is action, s is current state, s' is next state\n",
    "P = np.zeros((2, num_states, num_states))\n",
    "\n",
    "# Calculate P0 (Do nothing)\n",
    "for idx_s, s in enumerate(S):\n",
    "    T, d = s\n",
    "    \n",
    "    # Cannot do nothing in failed state\n",
    "    if d == xi[T]:\n",
    "        continue\n",
    "        \n",
    "    for idx_s_prime, s_prime in enumerate(S):\n",
    "        T_prime, d_prime = s_prime\n",
    "        \n",
    "        # Type cannot change under \"do nothing\"\n",
    "        if T != T_prime:\n",
    "            continue\n",
    "            \n",
    "        # Calculate transition probability based on degradation increase\n",
    "        if d <= d_prime < xi[T]:\n",
    "            P[0][idx_s][idx_s_prime] = zero_inflated_poisson_pmf(d_prime - d)\n",
    "        elif d < xi[T] and d_prime == xi[T]:\n",
    "            # Transition to failed state (cumulative probability of large increases)\n",
    "            cumulative_prob = 0\n",
    "            for k in range(xi[T] - d, max_k):\n",
    "                cumulative_prob += zero_inflated_poisson_pmf(k)\n",
    "            P[0][idx_s][idx_s_prime] = cumulative_prob\n",
    "\n",
    "# Calculate P1 (Do maintenance)\n",
    "for idx_s, s in enumerate(S):\n",
    "    for idx_s_prime, s_prime in enumerate(S):\n",
    "        (T_prime, d_prime) = s_prime\n",
    "        if d_prime == 0:\n",
    "            P[1][idx_s][idx_s_prime] = 1/3\n",
    "\n",
    "print(f\"Transition probability matrices created with shape: {P.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged at iteration 4\n",
      "Best policy [0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "gamma = 0.9\n",
    "\n",
    "# Initialize policy randomly\n",
    "policy = np.zeros(num_states, dtype=int)\n",
    "for s in range(num_states):\n",
    "    if C[s][0] == float(\"inf\"):\n",
    "        policy[s] = 1  # Use action 1 if action 0 is unavailable\n",
    "\n",
    "old_policy = np.ones_like(policy)\n",
    "iterations = 0\n",
    "\n",
    "while iterations == 0 or np.any(policy != old_policy):\n",
    "    iterations += 1\n",
    "    old_policy = policy.copy()\n",
    "\n",
    "    # Step 1\n",
    "    P_pi = np.zeros((num_states, num_states))\n",
    "    C_pi = np.zeros(num_states)\n",
    "    for s in range(num_states):\n",
    "        a = policy[s]\n",
    "        P_pi[s, :] = P[a][s]\n",
    "        C_pi[s] = C[s][a]\n",
    "    \n",
    "    I = np.identity(num_states)\n",
    "    V = np.linalg.inv(I - gamma * P_pi) @ C_pi\n",
    "\n",
    "    # Step 2\n",
    "    for s in range(num_states):\n",
    "        min_cost = float(\"inf\")\n",
    "        best_action = policy[s]\n",
    "        \n",
    "        for a in range(2):\n",
    "            if C[s][a] == float(\"inf\"):\n",
    "                continue  # Skip unavailable actions\n",
    "\n",
    "            expected_cost = C[s][a] + gamma * np.sum(P[a][s] * V)\n",
    "            \n",
    "            if expected_cost < min_cost:\n",
    "                min_cost = expected_cost\n",
    "                best_action = a\n",
    "        \n",
    "        policy[s] = best_action\n",
    "    \n",
    "print(f\"Converged at iteration {iterations}\")\n",
    "print(f\"Best policy {policy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Expected Discounted Costs for All States ===\n",
      "\n",
      "Type 1 Component:\n",
      "State (1,0): 0.9508\n",
      "State (1,1): 0.9992\n",
      "State (1,2): 1.0501\n",
      "State (1,3): 1.1020\n",
      "State (1,4): 1.1528\n",
      "State (1,5): 1.2036\n",
      "State (1,6): 1.2663\n",
      "State (1,7): 1.3715\n",
      "State (1,8): 1.4736\n",
      "State (1,9): 1.4736\n",
      "State (1,10): 1.4736\n",
      "State (1,11): 1.4736\n",
      "State (1,12): 1.4736\n",
      "State (1,13): 1.4736\n",
      "State (1,14): 1.4736\n",
      "State (1,15): 5.4736\n",
      "\n",
      "Type 2 Component:\n",
      "State (2,0): 0.4563\n",
      "State (2,1): 0.4792\n",
      "State (2,2): 0.5032\n",
      "State (2,3): 0.5285\n",
      "State (2,4): 0.5550\n",
      "State (2,5): 0.5828\n",
      "State (2,6): 0.6121\n",
      "State (2,7): 0.6428\n",
      "State (2,8): 0.6750\n",
      "State (2,9): 0.7089\n",
      "State (2,10): 0.7445\n",
      "State (2,11): 0.7818\n",
      "State (2,12): 0.8210\n",
      "State (2,13): 0.8621\n",
      "State (2,14): 0.9053\n",
      "State (2,15): 0.9508\n",
      "State (2,16): 0.9992\n",
      "State (2,17): 1.0501\n",
      "State (2,18): 1.1020\n",
      "State (2,19): 1.1528\n",
      "State (2,20): 1.2036\n",
      "State (2,21): 1.2663\n",
      "State (2,22): 1.3715\n",
      "State (2,23): 1.4736\n",
      "State (2,24): 1.4736\n",
      "State (2,25): 1.4736\n",
      "State (2,26): 1.4736\n",
      "State (2,27): 1.4736\n",
      "State (2,28): 1.4736\n",
      "State (2,29): 1.4736\n",
      "State (2,30): 5.4736\n",
      "\n",
      "Type 3 Component:\n",
      "State (3,0): 0.1714\n",
      "State (3,1): 0.1800\n",
      "State (3,2): 0.1891\n",
      "State (3,3): 0.1985\n",
      "State (3,4): 0.2085\n",
      "State (3,5): 0.2190\n",
      "State (3,6): 0.2299\n",
      "State (3,7): 0.2415\n",
      "State (3,8): 0.2536\n",
      "State (3,9): 0.2663\n",
      "State (3,10): 0.2797\n",
      "State (3,11): 0.2937\n",
      "State (3,12): 0.3084\n",
      "State (3,13): 0.3239\n",
      "State (3,14): 0.3402\n",
      "State (3,15): 0.3572\n",
      "State (3,16): 0.3752\n",
      "State (3,17): 0.3940\n",
      "State (3,18): 0.4137\n",
      "State (3,19): 0.4345\n",
      "State (3,20): 0.4563\n",
      "State (3,21): 0.4792\n",
      "State (3,22): 0.5032\n",
      "State (3,23): 0.5285\n",
      "State (3,24): 0.5550\n",
      "State (3,25): 0.5828\n",
      "State (3,26): 0.6121\n",
      "State (3,27): 0.6428\n",
      "State (3,28): 0.6750\n",
      "State (3,29): 0.7089\n",
      "State (3,30): 0.7445\n",
      "State (3,31): 0.7818\n",
      "State (3,32): 0.8210\n",
      "State (3,33): 0.8621\n",
      "State (3,34): 0.9053\n",
      "State (3,35): 0.9508\n",
      "State (3,36): 0.9992\n",
      "State (3,37): 1.0501\n",
      "State (3,38): 1.1020\n",
      "State (3,39): 1.1528\n",
      "State (3,40): 1.2036\n",
      "State (3,41): 1.2663\n",
      "State (3,42): 1.3715\n",
      "State (3,43): 1.4736\n",
      "State (3,44): 1.4736\n",
      "State (3,45): 1.4736\n",
      "State (3,46): 1.4736\n",
      "State (3,47): 1.4736\n",
      "State (3,48): 1.4736\n",
      "State (3,49): 1.4736\n",
      "State (3,50): 5.4736\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Expected Discounted Costs for All States ===\")\n",
    "\n",
    "# Type 1 states\n",
    "print(\"\\nType 1 Component:\")\n",
    "for d in range(16):  # Type 1 has states 0-15\n",
    "    state_idx = S.index((1, d))\n",
    "    print(f\"State (1,{d}): {V[state_idx]:.4f}\")\n",
    "\n",
    "# Type 2 states\n",
    "print(\"\\nType 2 Component:\")\n",
    "for d in range(31):  # Type 2 has states 0-30\n",
    "    state_idx = S.index((2, d))\n",
    "    print(f\"State (2,{d}): {V[state_idx]:.4f}\")\n",
    "\n",
    "# Type 3 states\n",
    "print(\"\\nType 3 Component:\")\n",
    "for d in range(51):  # Type 3 has states 0-50\n",
    "    state_idx = S.index((3, d))\n",
    "    print(f\"State (3,{d}): {V[state_idx]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ODMRL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
